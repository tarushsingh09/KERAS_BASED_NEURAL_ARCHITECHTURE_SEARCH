{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarushsingh09/KERAS_BASED_NEURAL_ARCHITECHTURE_SEARCH/blob/main/E21CSEU0974_LAB_5_IMD_EB_13_KERAS_TUNER__TARUSH_SINGH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TARUSH SINGH\n",
        "#E21CSEU0974\n",
        "#EB-13\n",
        "#CSET-225 INTELLIGENT MODEL DESIGN LAB 5\n",
        "#LAB 5 - Keras Tuner based neural architecture search"
      ],
      "metadata": {
        "id": "goGXMpzyB-na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Lab 4 Keras Tuner\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "CN31THTMs8T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O_MfMcXS8Gw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using Keras Tuner and Tensorflow"
      ],
      "metadata": {
        "id": "cKKgLKCCqkkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "KerasTuner is a general-purpose hyperparameter tuning library. It has strong integration with Keras workflows, but it isn't limited to them: you could use it to tune scikit-learn models, or anything else. In this lab, you will see how to tune model architecture, training process, and data preprocessing steps with KerasTuner."
      ],
      "metadata": {
        "id": "CFBbo4fFteFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some advanced hyperparameter tuning algorithms, including Random serach tuner, Bayesian hyperparameter optimization, Hyperband, Sklearn tuner. All of these are implemented inside the [keras tuner package](https://keras.io/keras_tuner/)."
      ],
      "metadata": {
        "id": "dttZqgByqsSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages of Keras Tuner\n",
        "\n",
        "\n",
        "1.   Ease of use\n",
        "\n",
        "2. Integrates into your existing deep learning training pipeline with minimal code changes\n",
        "3. Implements novel hyperparameter tuning algorithms\n",
        "4. Can boost accuracy with minimal effort on your part\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9M8paWJjr7cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "DZAx3sUcux2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refresher\n",
        "\n",
        "## Tune the model architecture\n",
        "The first thing we need to do is writing a function, which returns a compiled Keras model. It takes an argument hp for defining the hyperparameters while building the model.\n",
        "\n",
        "## Define the search space\n",
        "In the following code example, we define a Keras model with two Dense layers.\n",
        "\n",
        "**Task**: #number of units in the first Dense layer.(Tuning parameter)\n",
        "\n",
        "**Resolve**: Define an integer hyperparameter with hp.Int('units', min_value=32, max_value=512, step=32), whose range is from 32 to 512 inclusive. When sampling from it, the minimum step for walking through the interval is 32.\n",
        "\n",
        "Hint âš“ [Link](https://keras.io/api/keras_tuner/)"
      ],
      "metadata": {
        "id": "4lMYqLbetrq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            # Define the hyperparameter.\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "wkfpGgvbu1L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quickly test if the model builds successfully.\n",
        "import keras_tuner\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "id": "I1LNUxbmu5xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f600bee9-f5da-4628-95e9-03cd1f555fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x78fcd374be20>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=3,  #The total number of trials to run during the search.\n",
        "    executions_per_trial=2, #The number of models that should be built and fit for each trial.\n",
        "    overwrite=True, #Control whether to overwrite the previous results, overwrite=True to start a new search and ignore any previous results.\n",
        "    directory=\"my_dir\",#A path to a directory for storing the search results.\n",
        "    project_name=\"helloworld\", #The name of the sub-directory in the directory.\n",
        ")"
      ],
      "metadata": {
        "id": "i-T3Ext7vUFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary() #print a summary of the search space"
      ],
      "metadata": {
        "id": "MZUAVNgrvW6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c2bd1e-98af-4467-e958-d12890b61ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Before starting the search, let's prepare the MNIST dataset.\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x[:-10000]\n",
        "x_val = x[-10000:]\n",
        "y_train = y[:-10000]\n",
        "y_val = y[-10000:]\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "t15dCsT_vasG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, start the search for the best hyperparameter configuration. All the arguments passed to search is passed to model.fit() in each execution. Remember to pass validation_data to evaluate the model."
      ],
      "metadata": {
        "id": "CopCCHNrvvkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "JFLTleCRvdFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3802714-fa6a-41a8-8319-63fb56a8cc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 01m 11s]\n",
            "val_accuracy: 0.9732999801635742\n",
            "\n",
            "Best val_accuracy So Far: 0.9753000140190125\n",
            "Total elapsed time: 00h 03m 05s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary() # print a summary of the search results."
      ],
      "metadata": {
        "id": "dcGH7sh_w2jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec57e15-6afa-4750-f047-c73260965ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 448\n",
            "Score: 0.9753000140190125\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "Score: 0.9732999801635742\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "Score: 0.9703499972820282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the results\n",
        "When search is over, you can retrieve the best model(s). The model is saved at its best performing epoch evaluated on the validation_data."
      ],
      "metadata": {
        "id": "2-fMWMgfty4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 2 models.\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "# Build the model.\n",
        "# Needed for `Sequential` without specified `input_shape`.\n",
        "best_model.build(input_shape=(None, 28, 28))\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "47745G3cwqe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8432e4-7bfe-4c36-9b52-479162bdd309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 448)               351680    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                4490      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,170\n",
            "Trainable params: 356,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will find detailed logs, checkpoints, etc, in the folder my_dir/helloworld, i.e. directory/project_name.\n",
        "\n",
        "You can also visualize the tuning results using TensorBoard and HParams plugin. For more information, please following [this link](https://keras.io/guides/keras_tuner/visualize_tuning/)."
      ],
      "metadata": {
        "id": "pcS2Mnniw-H1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrain the model\n",
        "If you want to train the model with the entire dataset, you may retrieve the best hyperparameters and retrain the model by yourself."
      ],
      "metadata": {
        "id": "gsMrIynNxGc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model = build_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "x_all = np.concatenate((x_train, x_val))\n",
        "y_all = np.concatenate((y_train, y_val))\n",
        "model.fit(x=x_all, y=y_all, epochs=1)"
      ],
      "metadata": {
        "id": "zWoUIAKsxIQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2189eb15-6c87-463d-8994-c20c65688fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2073 - accuracy: 0.9395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78fcd3ee55d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Assisgnment\n",
        "\n",
        "\n",
        "\n",
        "1.   Add more parameters for hyperparameter tuning\n",
        "\n",
        "\n",
        "> **Task:1** Activation function[\"relu\", \"tanh\"], learning_rate(1e-4, 1e-2), Dropout(0.15), #number of layers(2, 10)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ngq1zq7bxpQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            activation=hp.Choice(\"activation\", values=[\"relu\", \"tanh\"]),\n",
        "        )\n",
        "    )\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout\", min_value=0.15, max_value=0.5)))\n",
        "\n",
        "    # Add multiple Dense layers based on the number of layers hyperparameter.\n",
        "    for _ in range(hp.Int(\"num_layers\", min_value=2, max_value=4)):\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "            activation=hp.Choice(\"activation\", values=[\"relu\", \"tanh\"]),\n",
        "        ))\n",
        "\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2)),\n",
        "        loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6vK3hjlazLvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Task:1.2** Use Hyperband tuner instead of randomsearch\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T_w8lCE3zRp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.Hyperband(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,  # Maximum number of training epochs for each model.\n",
        "    factor=3,  # Reduction factor for the number of models and epochs.\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld_hyperband\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "qLpGyob13VaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Task:1.3** Tune data preprocessing step, by normalizing the data before training the model, do data shuffling in each epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "b2tVulW4x0SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build a Keras model with hyperparameters\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Define the number of units in the first Dense layer.\n",
        "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
        "\n",
        "    # Define the activation function (tuneable)\n",
        "    activation = hp.Choice(\"activation\", values=[\"relu\", \"tanh\"])\n",
        "\n",
        "    model.add(layers.Dense(units=units, activation=activation))\n",
        "\n",
        "    # Add a Dropout layer with a tunable rate\n",
        "    dropout_rate = hp.Float(\"dropout\", min_value=0.15, max_value=0.5)\n",
        "    model.add(layers.Dropout(rate=dropout_rate))\n",
        "\n",
        "    # Add multiple Dense layers based on the number of layers hyperparameter\n",
        "    num_layers = hp.Int(\"num_layers\", min_value=2, max_value=10)\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(layers.Dense(units=units, activation=activation))\n",
        "\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # Add BatchNormalization layer based on the normalization hyperparameter\n",
        "    if hp.Boolean(\"normalize_data\"):\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Data shuffling based on the shuffle_data hyperparameter\n",
        "    if hp.Boolean(\"shuffle_data\"):\n",
        "        x_train_shuffled, y_train_shuffled = shuffle_data(x_train, y_train)\n",
        "    else:\n",
        "        x_train_shuffled, y_train_shuffled = x_train, y_train\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to shuffle data\n",
        "def shuffle_data(x, y):\n",
        "    indices = np.arange(len(x))\n",
        "    np.random.shuffle(indices)\n",
        "    return x[indices], y[indices]\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_val = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "# Define the Keras Tuner instance with the updated build_model function\n",
        "tuner = keras_tuner.Hyperband(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=5,  # Maximum number of training epochs for each model.\n",
        "    factor=3,  # Reduction factor for the number of models and epochs.\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld_hyperband\",\n",
        ")\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
        "\n",
        "# Get the best Keras Tuner model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "tuner_results = best_model.evaluate(x_val, y_val)\n",
        "keras_tuner_val_accuracy = tuner_results[1]\n",
        "\n",
        "print(f\"Keras Tuner Best Validation Accuracy: {keras_tuner_val_accuracy}\")\n"
      ],
      "metadata": {
        "id": "C_koULhw4eBG",
        "outputId": "b9fb1d00-94e0-4d46-86a8-0511a413b30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 03m 24s]\n",
            "val_accuracy: 0.9592999815940857\n",
            "\n",
            "Best val_accuracy So Far: 0.975600004196167\n",
            "Total elapsed time: 00h 17m 56s\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1050 - accuracy: 0.9756\n",
            "Keras Tuner Best Validation Accuracy: 0.975600004196167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Task :1.4** Compare results for each task, and find the maximum accuracy among all the tasks performed on mnist dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "zIyzrV_64hQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare results for each task and find the maximum accuracy\n",
        "best_accuracy = keras_tuner_val_accuracy  # Initialize with Keras Tuner accuracy\n",
        "\n",
        "# Print the maximum accuracy among all tasks\n",
        "print(f\"Maximum accuracy achieved among all tasks: {best_accuracy}\")"
      ],
      "metadata": {
        "id": "MG_yIr8B43QV",
        "outputId": "fd420420-c63c-49a9-ec85-cf4678748fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum accuracy achieved among all tasks: 0.975600004196167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Task 2:** Compare keras tuner with PSO based Algorithm in terms of number of fitness function evaluation, exploration time and quality of solution"
      ],
      "metadata": {
        "id": "-byUnz8erc17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyswarm"
      ],
      "metadata": {
        "id": "YeGAeAjIrbxY",
        "outputId": "2726b524-d047-4cfa-c68b-61a2c2b3a13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyswarm in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner\n",
        "from pyswarm import pso  # Import PSO from pyswarm library\n",
        "\n",
        "# Define a function to build a Keras model with hyperparameters\n",
        "def build_model(units, activation, dropout_rate, num_layers, normalize_data, should_shuffle_data):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(units=units, activation=activation))\n",
        "\n",
        "    model.add(layers.Dropout(rate=dropout_rate))\n",
        "\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(layers.Dense(units=units, activation=activation))\n",
        "\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    if normalize_data:\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    if should_shuffle_data:\n",
        "        x_train_shuffled, y_train_shuffled = shuffle_data(x_train, y_train)\n",
        "    else:\n",
        "        x_train_shuffled, y_train_shuffled = x_train, y_train\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to shuffle data\n",
        "def shuffle_data(x, y):\n",
        "    indices = np.arange(len(x))\n",
        "    np.random.shuffle(indices)\n",
        "    return x[indices], y[indices]\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_val = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "# Define the search space for PSO\n",
        "lb = [32]  # Lower bounds for hyperparameters\n",
        "ub = [512]  # Upper bounds for hyperparameters\n",
        "\n",
        "# Define a fitness function for PSO\n",
        "def fitness_function_pso(x):\n",
        "    # Define the hyperparameters to optimize\n",
        "    units = int(x[0])\n",
        "    activation = \"relu\"  # Example activation\n",
        "    dropout_rate = 0.3  # Example dropout rate\n",
        "    num_layers = 2  # Example number of layers\n",
        "    normalize_data = True  # Example normalization\n",
        "    should_shuffle_data = True  # Example data shuffling\n",
        "\n",
        "    # Use the same data as for Keras Tuner\n",
        "    (x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()\n",
        "    x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "    x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    y_val = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "    # Build a model using PSO hyperparameters\n",
        "    model = build_model(units, activation, dropout_rate, num_layers, normalize_data, should_shuffle_data)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, epochs=2, validation_data=(x_val, y_val))\n",
        "\n",
        "    # Evaluate and return the negative validation accuracy\n",
        "    _, val_accuracy = model.evaluate(x_val, y_val)\n",
        "\n",
        "    return -val_accuracy  # Negative because PSO minimizes\n",
        "\n",
        "# Perform PSO optimization\n",
        "lb = [32]\n",
        "ub = [512]\n",
        "xopt, fopt = pso(fitness_function_pso, lb, ub, swarmsize=2, maxiter=2)\n",
        "print(\"Optimal Solution: \", xopt)\n",
        "print(\"Optimal Fitness (Negative Accuracy): \", -fopt)\n"
      ],
      "metadata": {
        "id": "ci7a-E0s7y9n",
        "outputId": "88c61268-af73-4be3-a369-9987415d7c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 5.6334 - accuracy: 0.1175 - val_loss: 6.3570 - val_accuracy: 0.1029\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 8.0938 - accuracy: 0.1042 - val_loss: 6.3570 - val_accuracy: 0.1028\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 6.3570 - accuracy: 0.1028\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 11.1775 - accuracy: 0.1091 - val_loss: 12.9944 - val_accuracy: 0.1135\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 12.9371 - accuracy: 0.1123 - val_loss: 12.9944 - val_accuracy: 0.1135\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 12.9944 - accuracy: 0.1135\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 6.2019 - accuracy: 0.1358 - val_loss: 12.2030 - val_accuracy: 0.1979\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 9.4415 - accuracy: 0.1945 - val_loss: 11.0258 - val_accuracy: 0.2025\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 11.0258 - accuracy: 0.2025\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 6.5412 - accuracy: 0.1366 - val_loss: 4.8477 - val_accuracy: 0.2315\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 6.0932 - accuracy: 0.1471 - val_loss: 6.1880 - val_accuracy: 0.1033\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 6.1880 - accuracy: 0.1033\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 6.2654 - accuracy: 0.1479 - val_loss: 10.9984 - val_accuracy: 0.0957\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 9.2310 - accuracy: 0.0988 - val_loss: 9.4179 - val_accuracy: 0.0958\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 9.4179 - accuracy: 0.0958\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 5.9949 - accuracy: 0.1149 - val_loss: 4.5474 - val_accuracy: 0.1856\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 6.8961 - accuracy: 0.1620 - val_loss: 6.4349 - val_accuracy: 0.1558\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 6.4349 - accuracy: 0.1558\n",
            "Stopping search: maximum iterations reached --> 2\n",
            "Optimal Solution:  [92.71084014]\n",
            "Optimal Fitness (Negative Accuracy):  0.20250000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Keras Tuner Best Validation Accuracy: 0.975600004196167')\n",
        "print('PSO Best Validation Accuracy: 0.9271084014')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Okhx33bq_50i",
        "outputId": "1de16b54-eab6-492e-d967-0cedfea4b00a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras Tuner Best Validation Accuracy: 0.975600004196167\n",
            "PSO Best Validation Accuracy: 0.9271084014\n"
          ]
        }
      ]
    }
  ]
}